{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining Semantic Relations from Gutenberg\n",
    "\n",
    "I'm extracting information from Gutenberg data with SpaCy.  \n",
    "\n",
    "- `(possessor, possessed)`\n",
    "- `(noun, adjective, number_of_noun)`\n",
    "- `(noun, transitive_verb, number_of_noun)`\n",
    "\n",
    "\n",
    "The `transitive_verb` is lemmatized. `number_of_noun` is `1` (singular) or `2` (plural). From the sentence \"The small dog ate the purple leaves.\":\n",
    "\n",
    ">`[(\"small\",\"dog\",1),(\"purple\",\"leaves\",2)]`\n",
    "\n",
    "and \n",
    "\n",
    ">`[(\"dog\",\"eat\",1)]`\n",
    "\n",
    "***\n",
    "\n",
    "Todo\n",
    "\n",
    "* don't just get adjectives, also participles like \"cooked cabbage\" (maybe don't do this? yes...too many adjectives as it is...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det\n",
      "wild amod\n",
      "dog nsubj\n",
      "was ROOT\n",
      "small acomp\n",
      "and cc\n",
      "cold conj\n",
      ". punct\n",
      "  dep\n",
      "The det\n",
      "dog nsubj\n",
      "ate ROOT\n",
      "the det\n",
      "house dobj\n",
      ". punct\n",
      "  dep\n",
      "The det\n",
      "dog nsubj\n",
      "slept ROOT\n",
      ". punct\n",
      "The det\n",
      "tree nsubj\n",
      "bore ROOT\n",
      "fruit dobj\n",
      "and cc\n",
      "lemons conj\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "for a in nlp(\"The wild dog was small and cold.  The dog ate the house.  The dog slept. The tree bore fruit and lemons.\"):\n",
    "    print(a,a.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to extract relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting `(possessed,possessor)` tuples conservatively: trying to get relationships like \"the scales of the fish\" also gets \"ball of yarn.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 'legs'), ('king', 'mansions')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_possessor_possessed(tempspacy):\n",
    "    \"\"\"\n",
    "    For a sentence like \"The dog's fur, the teeth of the cat.\" returns [(dog, fur),(cat,teeth)].\n",
    "    lemmatizes the FIRST noun.  \n",
    "    \"\"\"\n",
    "    nouns = [\"NN\",\"NNS\"]\n",
    "    possessor_possessed_tuples = []\n",
    "    ### the the noun's possessed, the cat's meow\n",
    "    ### don't go for the meow of the cat because too ambiguous (the ball of yarn)\n",
    "    for token in tempspacy:\n",
    "#         try:\n",
    "        if (token.tag_ in nouns) and (token.head.tag_ in nouns): ### find a noun and its noun head\n",
    "            if token.dep_==\"poss\": ## make sure the dep that connects them is `poss`\n",
    "                possessor_possessed_tuples.append((token.text.lower(),token.head.text.lower()))\n",
    "#             if (token.tag_ in nouns) and (token.dep_==\"pobj\") and (token.head.lemma_==\"of\") and (token.head.head.tag_ in nouns):\n",
    "#                 possessor_possessed_tuples.append((token.head.head.text,token.text))\n",
    "#         except:\n",
    "#             pass\n",
    "    return possessor_possessed_tuples\n",
    "\n",
    "extract_possessor_possessed(nlp(u\"Beyond the old cat's stinky legs and ugly face.  A ball of yarn. The shining scales of the fish.  The king's mansions.  Your friend is here.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting `(possessed,possessor)` tuples conservatively: trying to get relationships like \"the scales of the fish\" also gets \"ball of yarn.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('small', 'frogs', 2), ('only', 'ones', 2), ('blue', 'bird', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_adj2nouns(tempspacy):\n",
    "    \"\"\"\n",
    "    returns [(adjective, noun, number of noun),...]\n",
    "    \"\"\"\n",
    "    nouns = [\"NN\",\"NNS\"]\n",
    "    adj_noun_tuples = []\n",
    "    for token in tempspacy:  ## for every token in the document\n",
    "        #print(token,token.dep_,token.pos_)\n",
    "#         try: \n",
    "        if token.dep_==\"amod\":  ## try to see if it is an `amod`, an adjective\n",
    "            if token.pos_==\"ADJ\":\n",
    "                if token.head.tag_ in nouns:  ## try to see if the head is a noun\n",
    "                    adj_noun_tuples.append((token.text.lower(),token.head.text.lower(),1 if token.head.tag_==\"NN\" else 2)) ## add the modifying word and the lemma \n",
    "#         except:\n",
    "#             pass\n",
    "    return adj_noun_tuples\n",
    "                                       \n",
    "extract_adj2nouns(nlp(\"Frogs and small frogs were not the only ones there, in the blue bird of the blue house.  The smiling dog walked itself through the house.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 'eat', 1), ('tree', 'bear', 1), ('dog', 'eat', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_noun2verb(tempspacy):\n",
    "    \"\"\"\n",
    "    returns [(noun, transitive verb, number of noun),...]\n",
    "    \"\"\"\n",
    "    \n",
    "    nouns = [\"NN\",\"NNS\"]\n",
    "\n",
    "    noun2verbs = []\n",
    "    \n",
    "    for token in tempspacy:\n",
    "#         try:\n",
    "        if ((token.tag_ in nouns) and (token.dep_==\"nsubj\")): ## find a noun subject\n",
    "            verb = token.head  ## make sure it's head is a verb\n",
    "            if verb.pos_ == \"VERB\":  ## ...\n",
    "                verb_children_deps = [c.dep_ for c in verb.children] ## make sure one of its deps has a dobj dependency\n",
    "                if \"dobj\" in verb_children_deps:\n",
    "                    obj = [c for c in verb.children if c.dep_==\"dobj\"][0] ## just get the last one\n",
    "                    noun2verbs.append((token.text.lower(),verb.lemma_,1 if token.tag_==\"NN\" else 2))# just noun and the verb lemma #obj.text.lower())) ## get the lemma, lemmatized verb, and nonlematized object\n",
    "#         except:\n",
    "#             pass\n",
    "    return noun2verbs\n",
    "\n",
    "\n",
    "extract_noun2verb(nlp(\"8:4 And the ark rested in the seventh month, on the seventeenth day of\\\n",
    "the month, upon the mountains of Ararat.And the ark rested in the seventh month, on the seventeenth day of the month, upon the mountains of Ararat. He swung through the fence.  The men circling the house. While running down the street, the man ate apples from a cart. The tree bore fruit and lemons. The dog who ran through the night ate chicken through the night.  The woods are on fire.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in some Gutenberg texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to loop through a bunch of Gutenberg texts that I've downloaded with the Gutenberg python package.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#directory = \"/Users/kyle/Documents/downloading_gutenberg/data/\"\n",
    "directory = \"/Volumes/extra_data/gutenberg/data/\"\n",
    "gb_files = [f for f in os.listdir(directory) if f.startswith('gb_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31116"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gb_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_testing = False ### False to run on all Gutenberg files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if just_testing==True:\n",
    "    gb_files = gb_files[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gutenberg.cleanup import strip_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 31116/31116 [31:42:27<00:00,  3.67s/it]\n"
     ]
    }
   ],
   "source": [
    "possessor2possessed = defaultdict(int)\n",
    "adj2nouns_tuples = defaultdict(int)\n",
    "noun2verb_tuples = defaultdict(int)\n",
    "banned_books = [\n",
    "    10,#bible...the verse numbers disturb spacy's parser\n",
    "]\n",
    "\n",
    "for fy in tqdm(gb_files):\n",
    "    with open(directory+fy,'r') as f:\n",
    "        tempdata = f.read()\n",
    "        filenumber = fy.lstrip(\"gb_\").rstrip(\".txt\")\n",
    "        if (\"Language: English\" in tempdata[:1000] and int(filenumber) not in banned_books):  ## make sure english \n",
    "            tempdata = strip_headers(tempdata)\n",
    "            tempdata = tempdata.replace(\"\\n\",\" \") ## important! spacy does better without \\n\n",
    "            tempspacy = nlp(tempdata[:200000])### limit to first n chars\n",
    "            try:\n",
    "                for pp in list(set(extract_possessor_possessed(tempspacy))):\n",
    "                    possessor2possessed[pp]+=1\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for pp in list(set(extract_adj2nouns(tempspacy))):\n",
    "                    adj2nouns_tuples[pp]+=1\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for pp in list(set(extract_noun2verb(tempspacy))):\n",
    "                    noun2verb_tuples[pp]+=1\n",
    "            except:\n",
    "                pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(possessor,possessed)` tuples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('strength', 'abundance'), 3),\n",
       " (('honour', 'ring'), 2),\n",
       " (('tongue', 'tune'), 2),\n",
       " (('father', 'skill'), 16),\n",
       " (('tiger', 'jaws'), 5),\n",
       " (('winter', 'deface'), 3),\n",
       " (('love', 'parts'), 4),\n",
       " (('love', 'face'), 17),\n",
       " (('eyes', 'falsehood'), 2),\n",
       " (('husband', 'shape'), 3)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(possessor2possessed.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1175185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(possessor2possessed.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('holy', 'writ', 1), 8),\n",
       " (('plausive', 'words', 2), 1),\n",
       " (('vulgar', 'thief', 1), 6),\n",
       " (('too', 'base', 1), 5),\n",
       " (('cold', 'fountain', 1), 10),\n",
       " (('mere', 'word', 1), 189),\n",
       " (('honourable', 'service', 1), 46),\n",
       " (('second', 'burthen', 1), 6),\n",
       " (('obedient', 'servant', 1), 816),\n",
       " (('antique', 'song', 1), 10)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(adj2nouns_tuples.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33418670"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(adj2nouns_tuples.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('grace', 'kill', 1), 2),\n",
       " (('child', 'sum', 1), 4),\n",
       " (('world', 'see', 1), 715),\n",
       " (('thou', 'find', 1), 132),\n",
       " (('unworthiness', 'raise', 1), 1),\n",
       " (('dreams', 'show', 2), 11),\n",
       " (('truth', 'need', 1), 27),\n",
       " (('death', 'do', 1), 112),\n",
       " (('ear', 'confound', 1), 4),\n",
       " (('beauty', 'hold', 1), 44)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(noun2verb_tuples.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4961751"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(noun2verb_tuples.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if just_testing==False:\n",
    "    with open(\"possessor2possessed_tuples_with_count.json\",\"w\") as f:\n",
    "        json.dump(list(possessor2possessed.items()),f)\n",
    "else:\n",
    "    print(\"just a test; not saving data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5389214"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj2nouns_tuples_items = list(adj2noun_tuples.items())\n",
    "len(adj2nouns_tuples_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj2nouns_tuples_at_least_2 = [(t,count) for (t,count) in adj2nouns_tuples_items if count>=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2126931"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj2nouns_tuples_at_least_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if just_testing==False:\n",
    "    with open(\"adj2nouns_tuples_with_count.json\",\"w\") as f:\n",
    "        json.dump(list(adj2nouns_tuples_at_least_2),f)\n",
    "else:\n",
    "    print(\"just a test; not saving data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if just_testing==False:\n",
    "    with open(\"noun2verb_tuples_with_count.json\",\"w\") as f:\n",
    "        json.dump(list(noun2verb_tuples.items()),f)\n",
    "else:\n",
    "    print(\"just a test; not saving data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ek",
   "language": "python",
   "name": "ek"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
